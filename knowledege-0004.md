## 1. 記事タイトル
【AI性能比較】LLM 評価指標をざっくり解説｜Artificial Analysis の歩き方

## 2. 公開日・更新日
公開日：2026年02月23日（最終更新：2026年02月23日）

## 3. 内容要約

**・全体を貫くメインテーマ**
LLM（大規模言語モデル）の性能・速度・コストを横断的に比較できるサイト「Artificial Analysis」で採用されている難解な評価指標を、4つのカテゴリ（仕事の完遂力、技術的専門性、知識と正確さ、地頭の良さ）に分類して初心者向けに分かりやすく解説する。

**・具体的な重要ポイント**
* **Artificial Analysisの有用性：** 単なるベンチマークスコアだけでなく、スループットや価格も含めた「実用性」でモデルを選別できるツール。
* **総合スコア「Intelligence Index」：** 複数の難関テストを統合したAIの「総合偏差値」。精度飽和を防ぐため、常に難しいテストへ入れ替えられる厳しい基準（2026年2月時点のトップでも50〜60点台）。
* **「賢さ」と「実務力」の乖離：** 学術的な推論（GPQA）で首位のモデルが、実務タスク（GDPval-AA）では下位になるなど、指標によって得意不得意が明確に分かれる現状を可視化。
* **主要な個別指標の紹介：** 実務力を測る「GDPval-AA」、エンジニア向け「Terminal-Bench Hard」、科学計算「SciCode」、地頭の良さを測る「GPQA Diamond」などの特徴と現状のスコア傾向を解説。

**・筆者の結論や読者へのアドバイス**
「どのAIが最強か」は用途によって異なります。エージェント化なら「Agentic Workflows」、専門研究なら「Technical Capability」といった具合に、目的に合った指標を確認することが重要です。Artificial Analysisを活用することで、モデルのリリースのたびに一喜一憂せず、データに基づいた冷静なモデル選定が可能になります。

## 4. 🔗 記事URL
https://qiita.com/Ryo-Nakano/items/f1da76e039071d7b5ebc
